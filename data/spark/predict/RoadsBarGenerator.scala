package data.spark.predict

import org.apache.spark.sql.{SparkSession, functions => F}

/**
 * ğŸ¯ åŠŸèƒ½ç›®æ ‡ï¼šä¸»è¦è·¯æ®µé¢„æµ‹æŸ±çŠ¶å›¾
 * å¯¹åº” predict.html é¡µé¢ä¸­ä¸Šå›¾è¡¨ï¼ˆJS: roads_bar.jsï¼‰ï¼Œç”¨äºå±•ç¤ºä¸åŒè·¯æ®µçš„æ‹¥å µé¢„æµ‹å€¼æ’è¡Œã€‚
 * */

object RoadsBarGenerator {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder()
      .appName("Roads Bar Generator")
      .master("local[*]")
      .getOrCreate()

    import spark.implicits._

    // Step 1: è¯»å–é¢„æµ‹åŸå§‹æ•°æ®
    val df = spark.read
      .option("header", "true")
      .option("inferSchema", "true")
      .csv("src/main/Scala/data/spark/predict_events.csv")

    // Step 2: è·å–æœ€æ–°é¢„æµ‹æ—¥æœŸ
    val latestDate = df.filter($"type" === "é¢„æµ‹")
      .agg(F.max("date")).as[String].collect()(0)

    // Step 3: æŒ‰ road èšåˆæ‹¥å µæŒ‡æ•°
    val filtered = df.filter($"type" === "é¢„æµ‹" && $"date" === latestDate)

    val roadAvg = filtered.groupBy("road")
      .agg(F.round(F.avg("congestion_index"), 1).alias("index"))
      .orderBy($"index".desc)

    // Step 4: è¾“å‡ºå‰ 10 ä¸ªè·¯æ®µï¼ˆå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
    val topRoads = roadAvg.limit(10)

    // Step 5: ä¿å­˜ä¸º JSON
    topRoads.coalesce(1)
      .write.mode("overwrite")
      .json("src/main/Scala/data/spark/predict/output/roads_bar")    // Step 5: ä¿å­˜ä¸º JSON
    topRoads.coalesce(1)
      .write.mode("overwrite")
      .csv("src/main/Scala/data/spark/predict/output/roads_bar2")

    spark.stop()
  }
}

